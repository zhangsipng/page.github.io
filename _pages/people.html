---
layout: archive
#title: "Talks and presentations"
permalink: /research/
author_profile: true
---

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NERCMS-MMAP - Multimedia Analysis and Processing Group</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 1px solid #ddd;
        }
        
        h1 {
            font-size: 28px;
            margin-bottom: 10px;
        }
        
        h2 {
            font-size: 22px;
            margin: 30px 0 15px;
            padding-bottom: 8px;
            border-bottom: 1px solid #eee;
        }
        
        h3 {
            font-size: 18px;
            margin: 15px 0 10px;
        }
        
        section {
            margin-bottom: 40px;
        }
        
        .leader-info {
            margin: 20px 0;
            padding: 15px;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        
        .team-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        
        .team-member {
            padding: 15px;
            border: 1px solid #eee;
            border-radius: 4px;
        }
        
        .member-name {
            font-weight: bold;
            margin-bottom: 5px;
        }
        
        .member-role {
            color: #666;
            margin-bottom: 8px;
        }
        
        .research-list {
            margin-left: 20px;
        }
        
        .research-list li {
            margin-bottom: 10px;
        }
        
        .achievement-item {
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 1px solid #f0f0f0;
        }
        
        .achievement-title {
            font-weight: bold;
            margin-bottom: 5px;
        }
        
        .achievement-meta {
            font-size: 14px;
            color: #666;
            margin-top: 5px;
        }
        
        footer {
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #666;
        }
        
        @media (max-width: 768px) {
            .team-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header>
        <h1>NERCMS-MMAP</h1>
        <p>Multimedia Analysis and Processing Group</p>
    </header>

    <!-- Team Members Section -->
    <section id="team">
        <h2>Team Members</h2>
        <div class="team-grid">
            <div class="team-member">
                <div class="member-name">Chao Liang</div>
                <div class="member-role">Professor, PhD Supervisor</div>
                <div class="member-research">Research: Computer Vision, Pattern Recognition, Multimedia Analysis</div>
            </div>
            <div class="team-member">
                <div class="member-name">Qiling Wu</div>
                <div class="member-role">Master's Student (2025)</div>
                <div class="member-research">Research: Surveillance Video Analysis</div>
            </div>
            <div class="team-member">
                <div class="member-name">Na Wang</div>
                <div class="member-role">Master's Student (2025)</div>
                <div class="member-research">Research: Film and TV Drama Analysis</div>
            </div>
            <div class="team-member">
                <div class="member-name">Haixiang Ni</div>
                <div class="member-role">Master's Student (2025)</div>
                <div class="member-research">Research: Network Attack and Defense</div>
            </div>
            <div class="team-member">
                <div class="member-name">Yu Zhang</div>
                <div class="member-role">PhD Student</div>
                <div class="member-research">Research: Interactive Instance Retrieval, Active Learning</div>
            </div>
            <div class="team-member">
                <div class="member-name">Ruizhe Li</div>
                <div class="member-role">PhD Student</div>
                <div class="member-research">Research: Deep Video Understanding, Instance Search</div>
            </div>
            <div class="team-member">
                <div class="member-name">Jiahao Guo</div>
                <div class="member-role">PhD Student</div>
                <div class="member-research">Research: Composite Semantic Instance Retrieval</div>
            </div>
            <div class="team-member">
                <div class="member-name">Mingxi Li</div>
                <div class="member-role">Master's Student</div>
                <div class="member-research">Research: Video Understanding and Analysis</div>
            </div>
            <div class="team-member">
                <div class="member-name">Zhengqian Wu</div>
                <div class="member-role">Master's Student</div>
                <div class="member-research">Research: Video Understanding Dataset Construction</div>
            </div>
            <div class="team-member">
                <div class="member-name">Jiangshan He</div>
                <div class="member-role">Master's Student</div>
                <div class="member-research">Research: Video Retrieval Systems</div>
            </div>
            <div class="team-member">
                <div class="member-name">Kai Xu</div>
                <div class="member-role">PhD Student</div>
                <div class="member-research">Research: Adversarial Defense, Face Recognition Security</div>
            </div>
            <div class="team-member">
                <div class="member-name">Jun Zhou</div>
                <div class="member-role">PhD Student</div>
                <div class="member-research">Research: Face Recognition Adversarial Defense</div>
            </div>
            <div class="team-member">
                <div class="member-name">Zhi Chen</div>
                <div class="member-role">Master's Student</div>
                <div class="member-research">Research: Adversarial Purification Defense</div>
            </div>
            <div class="team-member">
                <div class="member-name">Wentao Wen</div>
                <div class="member-role">Master's Student</div>
                <div class="member-research">Research: Multimodal Floor Plan Restoration</div>
            </div>
            <div class="team-member">
                <div class="member-name">Yu Fu</div>
                <div class="member-role">Master's Student</div>
                <div class="member-research">Research: Multimodal Technology Applications</div>
            </div>
            <div class="team-member">
                <div class="member-name">Chen Xiao</div>
                <div class="member-role">Master's Student</div>
                <div class="member-research">Research: Information Security and Multimedia</div>
            </div>
            <div class="team-member">
                <div class="member-name">Yu Niu</div>
                <div class="member-role">Graduate</div>
                <div class="member-research">Research: Instance Search</div>
            </div>
            <div class="team-member">
                <div class="member-name">Jian Yang</div>
                <div class="member-role">Graduate</div>
                <div class="member-research">Research: Video Content Analysis</div>
            </div>
            <div class="team-member">
                <div class="member-name">Ankang Lu</div>
                <div class="member-role">Graduate</div>
                <div class="member-research">Research: Composite Semantic Retrieval</div>
            </div>
            <div class="team-member">
                <div class="member-name">Weixi Song</div>
                <div class="member-role">Graduate</div>
                <div class="member-research">Research: Interactive Video Search</div>
            </div>
            <div class="team-member">
                <div class="member-name">Xinghan Li</div>
                <div class="member-role">Graduate</div>
                <div class="member-research">Research: Video Retrieval Systems</div>
            </div>
            <div class="team-member">
                <div class="member-name">Shiwei Feng</div>
                <div class="member-role">Graduate</div>
                <div class="member-research">Research: Multimedia Systems</div>
            </div>
            <div class="team-member">
                <div class="member-name">Yun Zhang</div>
                <div class="member-role">Graduate</div>
                <div class="member-research">Research: Domain Adaptation</div>
            </div>
            <div class="team-member">
                <div class="member-name">Zhongyuan Wang</div>
                <div class="member-role">Collaborative Researcher</div>
                <div class="member-research">Research: Computer Vision</div>
            </div>
            <div class="team-member">
                <div class="member-name">Zhi Han</div>
                <div class="member-role">Collaborative Researcher</div>
                <div class="member-research">Research: Pattern Recognition</div>
            </div>
        </div>
    </section>

    <!-- Research Areas Section -->
    <!--<section id="research">
        <h2>Research Areas</h2>
        <ul class="research-list">
            <li><strong>Video Understanding and Analysis</strong> - Including film and TV drama analysis, deep video understanding, instance search, focusing on extracting and understanding complex semantic information from videos.</li>
            <li><strong>Computer Vision and Pattern Recognition</strong> - Covering face recognition, adversarial defense, multimodal learning, studying the representation, recognition and understanding of visual information.</li>
            <li><strong>Multimedia Content Retrieval</strong> - Focusing on instance search, interactive retrieval and composite semantic retrieval technologies for large-scale video databases.</li>
            <li><strong>Artificial Intelligence Security</strong> - Researching adversarial attacks and defenses, model robustness evaluation, large model security to ensure the reliability and security of AI systems.</li>
            <li><strong>Multimodal Technology Applications</strong> - Exploring the potential of multimodal learning in practical applications such as floor plan restoration.</li>
        </ul>
    </section>
-->
    <!-- Achievements Section -->
  <!--  <section id="achievements">
        <h2>Research Achievements</h2>
        
        <div class="achievement-item">
            <div class="achievement-title">TRECVID 2023 AVS and DVU Dual Task Champion</div>
            <p>Achieved 29.2% and 29.9% accuracy in automatic retrieval and interactive retrieval tracks respectively, ranking first in competition with research institutions including City University of Hong Kong, Renmin University of China, Waseda University, and National Institute of Informatics Japan.</p>
            <div class="achievement-meta">He J, Li R, Guo J, et al. "WHU-NERCMS AT TRECVID 2023: AD-HOC VEDIO SEARCH (AVS) AND DEEP VIDEO UNDERSTANDING (DVU) TASKS." 2023.</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">ACM Multimedia 2023 Grand Challenge</div>
            <p>First participation in the DVU Challenge jointly organized by TRECVID and ACM Multimedia in 2023. Achieved two first places and two second places in four group tracks, with the highest total score in competition with established teams from Nanjing University, Beijing University of Posts and Telecommunications, etc.</p>
            <div class="achievement-meta">Li R, Guo J, Li M, et al. "A Hierarchical Deep Video Understanding Method with Shot-Based Instance Search and Large Language Model." In Proceedings of the 31st ACM International Conference on Multimedia, pp. 9425-9429. 2023. (CCF A Conference)</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">"Person-Action-Location" Triple Composite Semantic Instance Retrieval</div>
            <p>Achieved higher accuracy than the latest VLM models on three large-scale TV drama datasets (totaling 670,000 shots), ranking first.</p>
            <div class="achievement-meta">Jiahao Guo, Ankang Lu, Zhengqian Wu, Zhongyuan Wang and Chao Liang, "Who, What and Where: Composite-Semantics Instance Search for Story Videos," in IEEE Transactions on Image Processing, doi: 10.1109/TIP.2025.3542272. (CCF A Journal, SCI Q1 Journal)</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">Ensemble Criterion and Prototype Optimization-based Adversarial Attack Algorithm for Large Language Models</div>
            <p>Designed an efficient attack algorithm to induce large models to output prohibited content, helping to identify security vulnerabilities. Won first prize in the National Finals of the 6th "Huawei Cup" China Graduate AI Innovation Competition in September 2024 (winning rate about 2.3%).</p>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">Networked Surveillance-based Intelligent Digital Twin Platform</div>
            <p>Developed a digital twin platform based on networked surveillance to carry realistic intelligent applications. Won second prize in the 6th "Huawei Cup" China Graduate AI Innovation Competition in September 2024.</p>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">Tencent Kaiwu AI Global Open Competition</div>
            <p>Won second place in the Finals of the Mobile AI Model Lightweight Deployment Track in the Tencent Kaiwu AI Global Open Competition in October 2024. Enabled small-parameter models to inherit the reasoning ability of large-parameter models through knowledge distillation, greatly reducing computational costs.</p>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">TRECVID 2021 INS Task Champion</div>
            <p>Achieved 43.5% and 46.5% accuracy on two levels respectively, ranking first in competition with established teams from Peking University, Beijing University of Posts and Telecommunications, etc.</p>
            <div class="achievement-meta">Niu Y, Yang J, Lu A, et al. "WHU-NERCMS AT TRECVID2021 : INSTANCE SEARCH TASK." 2021.</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">Video Browser Shutdown 2023 Best Newcomer Award</div>
            <p>First participation in the international video content retrieval competition in 2023, ranking first in the newcomer group and winning the Best Newcomer Award.</p>
            <div class="achievement-meta">Weixi Song, Xinghan Li, Jiangshan He, Shiwei Feng, Chao Liang*, "QIVISE: A Quantum-inspired Interactive Video Search Engine in VBS2023", International Conference on Multimedia Modeling (MMM), 2023</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">FriendsQA: Automatically Constructed Large-scale Deep Video Understanding Dataset</div>
            <p>40 times larger than existing datasets, containing 44.6K questions, providing important resources for deep video understanding research.</p>
            <div class="achievement-meta">Wu Z, Li R, Xu Z, et al. FriendsQA: A New Large-Scale Deep Video Understanding Dataset with Fine-grained Topic Categorization for Story Videos[C] // The 39th Annual AAAI Conference on Artificial Intelligence. 2025. (CCF A Conference)</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">A-VAE: Manifold Projection-based Adversarial Defense Method for Face Recognition</div>
            <p>Compared with existing input transformation defenses, achieves better resistance to adversarial attacks in face recognition tasks.</p>
            <div class="achievement-meta">J. Zhou, C. Liang, J. Chen. "Manifold projection for adversarial defense on face recognition." In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXX 16, pp. 288-305. Springer International Publishing, 2020.</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">IMA: Multi-scale Attention Adversarial Purification Defense Method</div>
            <p>Outperforms current state-of-the-art methods across multiple datasets and varying attack intensities.</p>
            <div class="achievement-meta">K. Xu, Z. Chen, Z. Wang, C. Xiao and C. Liang, "Toward Robust Adversarial Purification for Face Recognition Under Intensity-Unknown Attacks," in IEEE Transactions on Information Forensics and Security (TIFS), vol. 19, pp. 9550-9565, 2024. (CCF-A, SCI Q1)</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">AIMER: Multi-exit Neural Network Robustness Evaluation Scheme in Game Framework</div>
            <p>Uses game theory framework to ensure evaluation of more realistic (lower) network robustness.</p>
            <div class="achievement-meta">K. Xu, C. Zhang, Z. Chen, Z. Wang, C. Xiao and C. Liang, "Rethinking the Adversarial Robustness of Multi-Exit Neural Networks in an Attack-Defense Game," In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025. (CCF A Conference)</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">Link-based Contrastive Learning for One-Shot Unsupervised Domain Adaptation</div>
            <p>Compared with existing unsupervised domain adaptation methods, achieves outstanding results in one-shot surveillance face recognition tasks.</p>
            <div class="achievement-meta">Y. Zhang, M. Bin, Y. Zhang, Z. Wang, Z. Han, C. Liang, "Link-based Contrastive Learning for One-Shot Unsupervised Domain Adaptation." In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025 (CCF A Conference)</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">Confidence-Aware Active Feedback for Interactive Instance Search</div>
            <p>Compared with existing active learning methods, generates higher quality feedback with less time consumption in interactive instance retrieval tasks.</p>
            <div class="achievement-meta">Y. Zhang, C. Liang, L. Jiang. "Confidence-Aware Active Feedback for Interactive Instance Search." In IEEE Transactions on Multimedia, vol. 25, pp. 7173-7184, 2023, doi: 10.1109/TMM.2022.3217965. (SCI Q1 Journal)</div>
        </div>
        
        <div class="achievement-item">
            <div class="achievement-title">Efficient Multimodal Floor Plan Restoration Technology</div>
            <p>Restoration time less than 1 second, accuracy higher than industry standards.</p>
            <div class="achievement-meta">T. Wen, Y. Fu, C. Xiao, H. Xiang and C. Liang, "Floor Plan Restoration: A Multimodal Method Under One Second," in IEEE Transactions on Visualization and Computer Graphics, doi: 10.1109/TVCG.2025.3539497. (CCF A Journal, SCI Q1 Journal)</div>
        </div>
    </section>
-->
    <!-- Footer -->
    <footer>
        <p>© 2024 NERCMS-MMAP Multimedia Analysis and Processing Group | Wuhan University</p>
        <p><a href="http://multimedia.whu.edu.cn/index.php?a=show&catid=69&id=131&lang=2&lang=1">Lab Homepage</a></p>
    </footer>
</body>
</html>

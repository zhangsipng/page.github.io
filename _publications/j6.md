---
title: "Correlation Discrepancy Insight Network for Video Re-identification"
collection: publications
category: manuscripts
date: 2020-01-01
venue: 'ACM Transactions on Multimedia Computing, Communication and Applications (TOMM)'
authors: Weijian Ruan, <b>Chao Liang</b>*, Yi Yu, Zheng Wang, Wu Liu, Jun Chen, Jiayi Ma
paperurl: https://dl.acm.org/doi/10.1145/3402666
bibtex: "@article{10.1145/3402666,
author = {Ruan, Weijian and Liang, Chao and Yu, Yi and Wang, Zheng and Liu, Wu and Chen, Jun and Ma, Jiayi},
title = {Correlation Discrepancy Insight Network for Video Re-identification},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1551-6857},
url = {https://doi.org/10.1145/3402666},
doi = {10.1145/3402666},
abstract = {Video-based person re-identification (ReID) aims at re-identifying a specified person sequence from videos that were captured by disjoint cameras. Most existing works on this task ignore the quality discrepancy across frames by using all video frames to develop a ReID method. Additionally, they adopt only the person self-characteristic as the representation, which cannot adapt to cross-camera variation effectively. To that end, we propose a novel correlation discrepancy insight network for video-based person ReID, which consists of an unsupervised correlation insight model (CIM) for video purification and a discrepancy description network (DDN) for person representation. Concretely, CIM is constructed by using kernelized correlation filters to encode person half-parts, which evaluates the frame quality by the cross correlation across frames for selecting discriminative video fragments. Furthermore, DDN exploits the selected video fragments to generate a discrepancy descriptor using a compression network, which aims at employing the discrepancies with other personsâ€™ to facilitate the representation of the target person rather than only using the self-characteristic. Due to the advantage in handling cross-domain variation, the discrepancy descriptor is expected to provide a new pattern for the object representation in cross-camera tasks. Experimental results on three public benchmarks demonstrate that the proposed method outperforms several state-of-the-art methods.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = dec,
articleno = {120},
numpages = {21},
keywords = {Video re-identification, correlation insight, cross-domain variation, discrepancy description network}
}"
---
